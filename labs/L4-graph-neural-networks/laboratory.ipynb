{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieci neuronowe - podstawy\n",
    "\n",
    "Do wytrenowania sieci neuronowej potrzebne są 3 elementy:\n",
    "\n",
    "1. architektura sieci,\n",
    "2. funkcja kosztu,\n",
    "3. metoda optymalizacji.\n",
    "\n",
    "Wszystkie te elementy można łatwo zaimplementować przy użyciu jednej z bibliotek do sieci neuronowych, np. PyTorch, TensorFlow lub JAX. Istnieją też biblioteki budowane na około tych najbardziej niskopoziomowych bibliotek, np. Keras lub Sonnet dla TensorFlow albo Haiku dla JAX-a. My na zajęciach będziemy używać PyTorcha orac PyTorch-Geometric do budowania sieci grafowych.\n",
    "\n",
    "## Architektura sieci (pojemność modelu i indukcyjne ukierunkowanie)\n",
    "\n",
    "Sieci neuronowe mają zwykle budowę warstwową, tzn. sieć składa się z sekwencji warstw które przekształcają kolejno reprezentację wejściową. Najpopularniejszą warstwą w sieciach neuronowych jest prawdopodobnie **warstwa liniowa** zwana też **w pełni połączoną** (ang. fully-connected). Każda cecha na wejściu jest połączona z każdą cechą na wyjściu warstwy, a siła tych połączeń jest uczona w trakcie treningu sieci. Ujmując to matematycznie, możemy napisać:\n",
    "\n",
    "$$\n",
    "[x_1, \\dots, x_n] \\cdot \\begin{bmatrix} \n",
    "w_{11} & \\cdots & w_{1m} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "w_{n1} & \\cdots & w_{nm}\n",
    "\\end{bmatrix} = \\mathbf{x}^T W = \\mathbf{y}^T =[y_1, \\dots, y_m],\n",
    "$$\n",
    "\n",
    "gdzie $\\mathbf{x}\\in\\mathbb{R}^n$ jest wejściem do warstwy, a $\\mathbf{y}\\in\\mathbb{R}^m$ to wyjście z warstwy. $W\\in\\mathbb{R}^{n\\times m}$ to parametry warstwy zwane **wagami**. Często dodawane jest jeszcze trenowalne przesunięcie (ang. bias) do wyniku przekształcenia, tj. $\\mathbf{x}^T W + \\mathbf{b}^T$. Zauważmy, że pojedyncze neurony wyjściowe spełniają równanie przypominające regresję liniową:\n",
    "\n",
    "$$\n",
    "y_k = x_1 w_{1k} + x_2 w_{2k} + \\cdots + x_n w_{nk} + b_k\n",
    "$$\n",
    "\n",
    "Drugim ważnym rodzajem warstw są warstwy nieliniowe. Zwykle nie mają one parametrów i służą jedynie wprowadzeniu nieliniowości do modelu. Gdyby nie te warstwy, sieć mogła by się nauczyć tylko zależności liniowych, tj. takich jak najprostsza regresja liniowa. Ze względu na efektywność najczęściej stosowaną obecnie nieliniowością jest **ReLU** (Rectified Linear Unit), o następującym wzorze:\n",
    "\n",
    "$$\n",
    "ReLU(x) = \\max(x,0) = \\begin{cases} x & \\text{dla } x \\geq 0,\\\\ 0 & \\text{dla } x < 0. \\end{cases}\n",
    "$$\n",
    "\n",
    "Inną ważną nieliniowością jest **sigmoid**, który jest mniej efektywny (wolniejszy w obliczeniu). Sigmoid był używany również w regresji logistycznej do klasyfikacji binarnej. Zwraca on liczby w przedziale (0, 1), które mogą być traktowane jako prawdopodobienstwo klasy pozytywnej.\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1+e^{-x}}\n",
    "$$\n",
    "\n",
    "## Funkcja kosztu (definicja problemu)\n",
    "\n",
    "Sama architektura definiuje tylko możliwości sieci, ale nie definiuje samego zadania. Do określenia, czego sieć ma się nauczyć, potrzebna nam będzie **funkcja kosztu** (ang. loss function). Będzie to cel optymalizacji, czyli funkcja, którą będziemy minimalizować (lub rzadziej maksymalizować) poprzez zmianę parametrów (wag) sieci neuronowej.\n",
    "\n",
    "Na przykład, dla problemu regresji standardową funkcją kosztu jest **błąd średniokwadratowy** (MSE - Mean Squared Error), który mierzy średni błąd każdej predykcji podniesiony do kwadratu:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathcal{X}|\\Theta)=\\mathrm{MSE}(\\mathcal{X}|\\Theta) = \\frac{1}{|\\mathcal{X}|} \\sum_{i=1}^{|\\mathcal{X}|} e_i^2 = \\frac{1}{|\\mathcal{X}|} \\sum_{i=1}^{|\\mathcal{X}|} (y_i - \\hat{y}_i)^2 = \\frac{1}{|\\mathcal{X}|} \\sum_{i=1}^{|\\mathcal{X}|} (y_i - f(\\mathbf{x}_i|\\Theta))^2\n",
    "$$ \n",
    "\n",
    "Będziemy tę funkcję minimalizować względem parametrów $\\Theta$, czyli wag sieci neuronowej.\n",
    "\n",
    "$$\n",
    "\\Theta^* = {\\arg \\min}_\\Theta \\,\\, \\mathcal{L}(\\mathcal{X}|\\Theta)\n",
    "$$\n",
    "\n",
    "## Metody optymalizacji (algorytm uczenia)\n",
    "\n",
    "Mając zdefiniowaną architekturę i cel, trzeb jeszcze dobrać algorytm poszukujący optymalnych parametrów. W klasycznym uczeniu maszynowym często mieliśmy wyprowadzone matematycznie wzory na optymalne parametry, jednak różnorodność sieci neuronowych i ich wielowarstwowość skutecznie utrudnia znajdowanie rozwiązań analitycznych.\n",
    "\n",
    "Z pomocą przychodzą metody optymalizacji gradientowej, które obliczają gradient funkcji kosztu względem parametrów, a następnie przesuwają te parametry w kierunku przeciwnym do gradientu (jeśli chcemy funkcję minimalizować). Jest to możliwe dzięki różniczkowalności wszystkich operacji w sieci oraz regule łańcuchowej.\n",
    "\n",
    "Najbardziej standardową metodą optymalizacji jest **SGD** (Stochastic Gradient Descent):\n",
    "\n",
    "$$\n",
    "\\Theta \\leftarrow \\Theta - \\eta \\nabla \\mathcal{L}(\\mathcal{X}|\\Theta),\n",
    "$$\n",
    "\n",
    "gdzie $\\eta$ to współczynnik uczenia (ang. learning rate), który należy dobrać odpowiednio do problemu (hiperparametr). Metoda SGD jest prawdopodobnie najbardziej podstawową, a w bibliotekach do sieci zaimplementowane są również późniejsze udoskonalenia tej techniki, np. **Momentum**, które dodatkowo akumuluje gradienty z przeszłości, aby przyspieszyć zbieżność metody i uniknąć lokalnych minimum.\n",
    "\n",
    "$$\n",
    "v \\leftarrow \\gamma v + \\eta \\nabla \\mathcal{L}(\\mathcal{X}|\\Theta), \\\\\n",
    "\\Theta \\leftarrow \\Theta - v.\n",
    "$$\n",
    "\n",
    "Stała momentum $\\gamma$ zwykle ustawiana jest na wartość 0.9 (powinna być mniejsza od 1, by pęd się powoli tracił).\n",
    "\n",
    "\n",
    "**Zadanie 1:** Uzupełnij kod do trenowania sieci o 3 wyżej wymienione komponenty. Kod ten używa fingerprintów Morgana (ECFP) do przewidywania rozpuszczalności związku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "from mldd.metrics import mae, rmse, rocauc, r_squared\n",
    "from mldd.data import *\n",
    "\n",
    "\n",
    "def train(X_train, y_train, X_valid, y_valid):\n",
    "    # hyperparameters definition\n",
    "    hidden_size = 512\n",
    "    epochs = 50\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.0001\n",
    "    \n",
    "    # model preparation\n",
    "    model = ...  # TODO\n",
    "    model.train()\n",
    "    \n",
    "    # data preparation\n",
    "    dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train.reshape(-1, 1)))\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # training loop\n",
    "    optimizer = ...  # TODO\n",
    "    loss_fn = ...  # TODO\n",
    "    for epoch in trange(1, epochs + 1, leave=False):\n",
    "        for X, y in tqdm(loader, leave=False):\n",
    "            model.zero_grad()\n",
    "            preds = model(X)\n",
    "            loss = loss_fn(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(model, X_test, y_test):\n",
    "    # hyperparameters definition\n",
    "    # (but this doesn't change the training results, it's only to optimize the eval speed)\n",
    "    batch_size = 64\n",
    "\n",
    "    # data preparation\n",
    "    dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test.reshape(-1, 1)))\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # evaluation loop\n",
    "    preds_batches = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(loader):\n",
    "            preds = model(X)\n",
    "            preds_batches.append(preds.cpu().detach().numpy())\n",
    "    preds = np.concatenate(preds_batches)\n",
    "    return preds\n",
    "\n",
    "\n",
    "df, fold_indices = load_esol()\n",
    "featurizer = ECFPFeaturizer(y_column='measured log solubility in mols per litre')\n",
    "scores = []\n",
    "for train_data, valid_data, test_data in cross_validate(df, fold_indices, preprocessing_fn=featurizer):\n",
    "    X_train, y_train = train_data\n",
    "    X_valid, y_valid = valid_data\n",
    "    X_test, y_test = test_data\n",
    "        \n",
    "    # training\n",
    "    model = train(X_train, y_train, X_valid, y_valid)\n",
    "    \n",
    "    # evaluation\n",
    "    predictions = predict(model, X_test, y_test)\n",
    "    \n",
    "    rmse_score = rmse(y_test, predictions)\n",
    "    mae_score = mae(y_test, predictions)\n",
    "    r2_score = r_squared(y_test, predictions)\n",
    "    scores.append([rmse_score, mae_score, r2_score])\n",
    "    \n",
    "    break  # can be removed to get results on all folds\n",
    "scores = np.array(scores)\n",
    "print('RMSE, MAE, R2 = ' + \\\n",
    "      ', '.join(f'{mean:.2f}±{std:.3f}' for mean, std in zip(scores.mean(axis=0), scores.std(axis=0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grafy molekularne\n",
    "\n",
    "**Przypomnienie:** W matematyce grafem nazywamy obiekt składający się ze zbioru wierzchołków połączonych krawędziami, czyli $\\mathcal{G} = (V, E)$, gdzie $V = \\{ v_i: i \\in \\{1, 2, \\dots, N \\} \\}$ oraz $E \\subseteq \\{ (v_i, v_j):\\, v_i,v_j \\in V \\}$.\n",
    "\n",
    "Grafy molekularne są specjalnego rodzaju grafami, gdzie oprócz wierzchołków (oznaczających atomy) i krawędzi (oznaczających wiązania chemiczne) mamy dodatkową informację o rodzaju atomów, a czasem także wiązań. Możemy zatem przyjąć, że dodatkowo mamy zestaw cech atomów zapisany jako macierz $X$, gdzie $X_{ij}$ to $j$-ta cecha $i$-tego atomu. Cechami mogą być zakodowane symbole atomów w postaci one-hot (1 na pozycji odpowiadającej danemu pierwiatkowi i 0 na pozostałych pozycjach), a także liczba wodorów związanych z atomem czy liczba tzw. ciężkich sąsiadów (atomów różnych od wodoru związanych z danym atomem).\n",
    "\n",
    "Krawędzie/wiązania mogą być zapisywane na różne sposoby. Popularnym zapisem jest macierz sąsiedztwa $A$, gdzie $A_{ij}=1$ oznacza, że wierzchołki/atomy $v_i$ oraz $v_j$ są ze sobą połączone (w przeciwnym wypadku $A_{ij}=0$). W przypadku macierzy rzadkich bardziej oszczędnym zapisem jest lista par połączonych ze sobą atomów (lista par indeksów). Ten drugi zapis używany jest też przez bibliotekę PyTorch-Geometric.\n",
    "\n",
    "W praktyce zatem graf molekularny można zapisać dwoma macierzami: $X \\in \\mathbb{R}^{N \\times F}$ oraz $E \\in \\{0, 1,\\dots,N-1\\}^{2 \\times N}$, gdzie $N$ to liczba atomów, a $F$ to liczba cech atomów.\n",
    "\n",
    "**Zadanie 2:** Stwórz zbiór grafów molekularnych w bibliotece PyTorch-Geometric, używając tych samych danych co w zadaniu 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise ValueError(\"input {0} not in allowable set{1}:\".format(\n",
    "            x, allowable_set))\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "\n",
    "class GraphFeaturizer(Featurizer):\n",
    "    def __call__(self, df):\n",
    "        graphs = []\n",
    "        labels = []\n",
    "        for i, row in df.iterrows():\n",
    "            y = row[self.y_column]\n",
    "            smiles = row.smiles\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            \n",
    "            edges = []\n",
    "            for bond in mol.GetBonds():\n",
    "                edges.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "                edges.append([bond.GetEndAtomIdx(), bond.GetBeginAtomIdx()])\n",
    "            edges = np.array(edges)\n",
    "            \n",
    "            nodes = []\n",
    "            for atom in mol.GetAtoms():\n",
    "                results = one_of_k_encoding_unk(\n",
    "                    atom.GetSymbol(),\n",
    "                    [\n",
    "                        'Br', 'C', 'Cl', 'F', 'H', 'I', 'N', 'O', 'P', 'S', 'Unknown'\n",
    "                    ]\n",
    "                ) + one_of_k_encoding(\n",
    "                    atom.GetDegree(),\n",
    "                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "                ) + one_of_k_encoding_unk(\n",
    "                    atom.GetImplicitValence(),\n",
    "                    [0, 1, 2, 3, 4, 5, 6]\n",
    "                ) + [atom.GetFormalCharge(), atom.GetNumRadicalElectrons()] + one_of_k_encoding_unk(\n",
    "                    atom.GetHybridization(),\n",
    "                    [\n",
    "                        Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "                        Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.SP3D,\n",
    "                        Chem.rdchem.HybridizationType.SP3D2\n",
    "                    ]\n",
    "                ) + [atom.GetIsAromatic()] + one_of_k_encoding_unk(\n",
    "                    atom.GetTotalNumHs(),\n",
    "                    [0, 1, 2, 3, 4]\n",
    "                )\n",
    "                nodes.append(results)\n",
    "            nodes = np.array(nodes)\n",
    "            \n",
    "            graphs.append((nodes, edges.T))\n",
    "            labels.append(y)\n",
    "        labels = np.array(labels)\n",
    "        return graphs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import ...  # TODO\n",
    "\n",
    "\n",
    "class GraphDataset(...):  # TODO\n",
    "    def __init__(self, X, y, root, transform=None, pre_transform=None):\n",
    "        self.dataset = (X, y)\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        data = []\n",
    "        ...  # TODO (data should be a list of graphs)\n",
    "        torch.save(data, self.raw_paths[0])\n",
    "        \n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = torch.load(self.raw_paths[0])\n",
    "        \n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grafowe sieci neuronowe\n",
    "\n",
    "Grafowe sieci neuronowe (GNN - Graph Neural Networks) potrafią przetwarzać grafy podane na wejściu modelu. Warstwa grafowa przyjmuje na wejściu graf z reprezentacjami poszczególnych atomów i zwraca na wyjściu graf o takiej samej strukturze (nie zmienia krawędzi) ale ze zaktualizowanymi reprezentacjami w wierzchołkach. W taki sposób możemy stworzyć sieć do **klasyfikacji wierzchołków** lub użyć operacji odczytu grafu przy pomocy wybranej funkcji agregującej wierzchołki, np. średniej. Wynikiem tej operacji będzie wektor opisujący cały graf, który może nam posłużyć do **klasyfikacji grafów**.\n",
    "\n",
    "## Message Passing Neural Networks (MPNN)\n",
    "\n",
    "MPNN jest bardzo ogólnym opisem sieci grafowej, do którego można dopasować wiele istniejących architektur sieci. W sieci MPNN wiadomości (ang. **message**) z sąsiednich wierzchołków są przesyłane do poszczególnych wierzchołków i zachodzi operacja aktualizacji reprezentacji (ang. **update**). Operacja ta jest powtarzana kilkukrotnie, a następnie dokonuje się odczytu (ang. **readout**) całego grafu.\n",
    "\n",
    "$$\n",
    "\\mathbf{m}_i^{t+1} = \\sum_{j\\in\\mathcal{N}(i)} M_t(\\mathbf{h}_i^t, \\mathbf{h}_j^t, \\mathbf{e}_{ij})\\\\\n",
    "\\mathbf{h}_i^{t+1} = U_t(\\mathbf{h}_i^t, \\mathbf{m}_i^{t+1}) \\\\\n",
    "\\hat{y} = R(\\{\\mathbf{h}_i^T \\, | \\, i \\in \\mathcal{G} \\})\n",
    "$$\n",
    "\n",
    "## Graph Convolutional Networks (GCN)\n",
    "\n",
    "Sieci konwolucyjne/splotowe działają na grafach podobnie jak na obrazach. Reprezentacje wszystkich wierzchołków w promieniu jednego wiązania są przemnażane przez wagi i sumowane. Dodatkowo wartości te są normalizowane uwzględniając stopień wierzchołka.\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{t+1} = W^T \\sum_{j\\in\\mathcal{N}(i)\\cup \\{i\\}} \\frac{e_{ij}}{\\sqrt{\\hat{d}_i \\hat{d}_j}} \\mathbf{h}_j^t\n",
    "$$\n",
    "\n",
    "## Graph Isomorphism Networks (GIN)\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{t+1} = W^T \\left( (1+\\varepsilon)\\mathbf{h}_i^t + \\sum_{j\\in\\mathcal{N}(i)} \\mathbf{h}_j^t \\right)\n",
    "$$\n",
    "\n",
    "## GraphSAGE\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{t+1} = W_1 \\mathbf{h}_i^t + W_2 \\frac{1}{|\\mathcal{N}(i)|} \\sum_{j\\in\\mathcal{N}(i)} \\mathbf{h}_j^t\n",
    "$$\n",
    "\n",
    "## Graph Attention Networks (GAT)\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{t+1} = \\sum_{j\\in\\mathcal{N}(i)\\cup \\{i\\}} \\alpha_{ij} W \\mathbf{h}_j^t,\\\\\n",
    "\\alpha_{ij} = \\frac{\\exp\\left( LeakyReLU(\\mathbf{a}[W\\mathbf{h}_i^t \\| W\\mathbf{h}_j^t])\\right)}{\\sum_{k\\in\\mathcal{N}(i) \\cup \\{i\\}}\\exp\\left( LeakyReLU(\\mathbf{a}[W\\mathbf{h}_i^t \\| W\\mathbf{h}_k^t])\\right)}\n",
    "$$\n",
    "\n",
    "**Zadanie 3:** Użyj przygotowanych grafów molekularnych do przewidywania rozpuszczalności."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da41c4635b0748998d86dda6fd5833f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE, MAE, R2 = 1.15±0.000, 0.87±0.000, 0.68±0.000\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader as GraphDataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, Sequential as GraphSequential\n",
    "\n",
    "\n",
    "def train(X_train, y_train, X_valid, y_valid):\n",
    "    # hyperparameters definition\n",
    "    hidden_size = 512\n",
    "    epochs = 50\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.0001\n",
    "    \n",
    "    # model preparation\n",
    "    model = ...  # TODO\n",
    "    model.train()\n",
    "    \n",
    "    # data preparation\n",
    "    dataset = GraphDataset(X_train, y_train.reshape(-1, 1), root='esol-train')\n",
    "    loader = GraphDataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # training loop\n",
    "    optimizer = ...  # TODO\n",
    "    loss_fn = ...  # TODO\n",
    "    for epoch in trange(1, epochs + 1, leave=False):\n",
    "        for data in tqdm(loader, leave=False):\n",
    "            x, edge_index, batch, y = data.x, data.edge_index, data.batch, data.y\n",
    "            \n",
    "            model.zero_grad()\n",
    "            preds = model(x, edge_index, batch)\n",
    "            loss = loss_fn(preds, y.reshape(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(model, X_test, y_test):\n",
    "    # hyperparameters definition\n",
    "    # (but this doesn't change the training results, it's only to optimize the eval speed)\n",
    "    batch_size = 64\n",
    "\n",
    "    # data preparation\n",
    "    dataset = GraphDataset(X_test, y_test.reshape(-1, 1), root='esol-test')\n",
    "    loader = GraphDataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # evaluation loop\n",
    "    preds_batches = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader):\n",
    "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "            \n",
    "            preds = model(x, edge_index, batch)\n",
    "            preds_batches.append(preds.cpu().detach().numpy())\n",
    "    preds = np.concatenate(preds_batches)\n",
    "    return preds\n",
    "\n",
    "\n",
    "df, fold_indices = load_esol()\n",
    "featurizer = GraphFeaturizer(y_column='measured log solubility in mols per litre')\n",
    "scores = []\n",
    "for train_data, valid_data, test_data in cross_validate(df, fold_indices, preprocessing_fn=featurizer):\n",
    "    X_train, y_train = train_data\n",
    "    X_valid, y_valid = valid_data\n",
    "    X_test, y_test = test_data\n",
    "            \n",
    "    # training\n",
    "    model = train(X_train, y_train, X_valid, y_valid)\n",
    "    \n",
    "    # evaluation\n",
    "    predictions = predict(model, X_test, y_test)\n",
    "    \n",
    "    rmse_score = rmse(y_test, predictions.flatten())\n",
    "    mae_score = mae(y_test, predictions.flatten())\n",
    "    r2_score = r_squared(y_test, predictions.flatten())\n",
    "    scores.append([rmse_score, mae_score, r2_score])\n",
    "    \n",
    "    break  # can be removed to get results on all folds\n",
    "scores = np.array(scores)\n",
    "print('RMSE, MAE, R2 = ' + \\\n",
    "      ', '.join(f'{mean:.2f}±{std:.3f}' for mean, std in zip(scores.mean(axis=0), scores.std(axis=0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Interpretowalność - Grad-CAM dla grafów\n",
    "\n",
    "$$\n",
    "\\alpha_k^{l,c}=\\frac{1}{N}\\sum_{n=1}^N \\frac{\\partial y^c}{\\partial F_{k,n}^l},\\\\\n",
    "L^c(l,n) = ReLU\\left(\\sum_k \\alpha_k^{l,c} F_{k,n}^l (X, A)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "        ...  # TODO\n",
    "    \n",
    "    def activations_hook(self, grad):\n",
    "        self.final_conv_grads = grad\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        ...  # TODO\n",
    "        with torch.enable_grad():\n",
    "            self.final_conv_acts = ...  # TODO\n",
    "        self.final_conv_acts.register_hook(self.activations_hook)\n",
    "        ...  # TODO\n",
    "        return ...  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader as GraphDataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, Sequential as GraphSequential\n",
    "\n",
    "\n",
    "def train(X_train, y_train, X_valid, y_valid):\n",
    "    # hyperparameters definition\n",
    "    hidden_size = 512\n",
    "    epochs = 50\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.0001\n",
    "    \n",
    "    # model preparation\n",
    "    model = ...  # TODO\n",
    "    model.train()\n",
    "    \n",
    "    # data preparation\n",
    "    dataset = GraphDataset(X_train, y_train.reshape(-1, 1), root='esol-train')\n",
    "    loader = GraphDataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # training loop\n",
    "    optimizer = ...  # TODO\n",
    "    loss_fn = ...  # TODO\n",
    "    for epoch in trange(1, epochs + 1, leave=False):\n",
    "        for data in tqdm(loader, leave=False):\n",
    "            x, edge_index, batch, y = data.x, data.edge_index, data.batch, data.y\n",
    "            \n",
    "            model.zero_grad()\n",
    "            preds = model(x, edge_index, batch)\n",
    "            loss = loss_fn(preds, y.reshape(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(model, X_test, y_test):\n",
    "    # hyperparameters definition\n",
    "    # (but this doesn't change the training results, it's only to optimize the eval speed)\n",
    "    batch_size = 64\n",
    "\n",
    "    # data preparation\n",
    "    dataset = GraphDataset(X_test, y_test.reshape(-1, 1), root='esol-test')\n",
    "    loader = GraphDataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # evaluation loop\n",
    "    preds_batches = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader):\n",
    "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "            \n",
    "            preds = model(x, edge_index, batch)\n",
    "            preds_batches.append(preds.cpu().detach().numpy())\n",
    "    preds = np.concatenate(preds_batches)\n",
    "    return preds\n",
    "\n",
    "\n",
    "df, fold_indices = load_esol()\n",
    "featurizer = GraphFeaturizer(y_column='measured log solubility in mols per litre')\n",
    "scores = []\n",
    "for train_data, valid_data, test_data in cross_validate(df, fold_indices, preprocessing_fn=featurizer):\n",
    "    X_train, y_train = train_data\n",
    "    X_valid, y_valid = valid_data\n",
    "    X_test, y_test = test_data\n",
    "            \n",
    "    # training\n",
    "    model = train(X_train, y_train, X_valid, y_valid)\n",
    "    \n",
    "    # evaluation\n",
    "    predictions = predict(model, X_test, y_test)\n",
    "    \n",
    "    rmse_score = rmse(y_test, predictions.flatten())\n",
    "    mae_score = mae(y_test, predictions.flatten())\n",
    "    r2_score = r_squared(y_test, predictions.flatten())\n",
    "    scores.append([rmse_score, mae_score, r2_score])\n",
    "    \n",
    "    break  # can be removed to get results on all folds\n",
    "scores = np.array(scores)\n",
    "print('RMSE, MAE, R2 = ' + \\\n",
    "      ', '.join(f'{mean:.2f}±{std:.3f}' for mean, std in zip(scores.mean(axis=0), scores.std(axis=0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def grad_cam(final_conv_acts, final_conv_grads):\n",
    "    node_heat_map = []\n",
    "    alphas = ...  # TODO (formula 1)\n",
    "    for n in range(final_conv_acts.shape[0]): # nth node\n",
    "        node_heat = ...  # TODO (formula 2)\n",
    "        node_heat_map.append(node_heat)\n",
    "    return node_heat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from IPython.display import SVG\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "compound_idx = 110\n",
    "mol = Chem.MolFromSmiles(df.iloc[fold_indices[0][compound_idx]].smiles)\n",
    "\n",
    "graph = test_data[0][compound_idx]\n",
    "X, E = graph\n",
    "data = Data(\n",
    "    x=torch.FloatTensor(X),\n",
    "    edge_index=torch.LongTensor(E)\n",
    ")\n",
    "\n",
    "x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "model(x, edge_index, torch.zeros(x.shape[0], dtype=torch.int64))\n",
    "atom_weights = grad_cam(model.final_conv_acts, model.final_conv_grads)\n",
    "\n",
    "atom_weights = np.array(atom_weights)\n",
    "if (atom_weights > 0.).any():\n",
    "    atom_weights = atom_weights / atom_weights.max() / 2\n",
    "\n",
    "if len(atom_weights) > 0:\n",
    "    norm = matplotlib.colors.Normalize(vmin=-1, vmax=1)\n",
    "    cmap = cm.get_cmap('bwr')\n",
    "    plt_colors = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    atom_colors = {\n",
    "        i: plt_colors.to_rgba(atom_weights[i]) for i in range(len(atom_weights))\n",
    "    }\n",
    "    highlight_kwargs = {\n",
    "        'highlightAtoms': list(range(len(atom_weights))),\n",
    "        'highlightBonds': [],\n",
    "        'highlightAtomColors': atom_colors\n",
    "    }\n",
    "\n",
    "d = rdMolDraw2D.MolDraw2DSVG(500, 500) # or MolDraw2DCairo to get PNGs\n",
    "rdMolDraw2D.PrepareAndDrawMolecule(d, mol, **highlight_kwargs)\n",
    "d.FinishDrawing()\n",
    "svg = d.GetDrawingText()\n",
    "svg = svg.replace('svg:', '')\n",
    "SVG(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
